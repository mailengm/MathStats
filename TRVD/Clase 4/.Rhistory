scale_color_manual(values = c("G=1" = "#EE349c", "G=2" = "#07004D"))  # Customize colors if needed
# Save the plot to a PDF file
ggsave("scatter_plot.pdf", plot = scatter_plot, width = 8, height = 3)
x_1_ <- sweep(x_1, 2, mu)
x_2_ <- sweep(x_2, 2, mu)
z_1 <- t(t(A)%*%t(x_1_))
z_2 <- t(t(A)%*%t(x_2_))
plot(z_1, col = '#EE3496', pch=16)
points(z_2, col = '#004D40', pch=16)
## Create the scatterplots of z_1 and z_2 using ggplot2
ggplot(data = data.frame(x = z_1), aes(x = x)) +
geom_point(color = 'red') +
labs(x = "X-axis", y = "Y-axis", title = "Scatterplot of z_1")
View(z_1)
## Create the scatterplots of z_1 and z_2 using ggplot2
ggplot(data = data.frame(x = z_1), aes(x = V1, y=V2)) +
geom_point(color = 'red') +
labs(x = "X-axis", y = "Y-axis", title = "Scatterplot of z_1")
## Create the scatterplots of z_1 and z_2 using ggplot2
ggplot(data = as.data.frame(z_1), aes(x = V1, y=V2)) +
geom_point(color = 'red') +
labs(x = "X-axis", y = "Y-axis", title = "Scatterplot of z_1")
## Create the scatterplots of z_1 and z_2 using ggplot2
ggplot(data = as.data.frame(z_1), aes(x = V1, y=V2)) +
geom_point(color = 'red') +
labs(x = "X-axis", y = "Y-axis", title = "Scatterplot of z_1")
ggplot(data = as.data.frame(z_2), aes(x = x)) +
geom_point(color = 'green') +
labs(x = "X-axis", y = "Y-axis", title = "Scatterplot of z_2")
## Create the scatterplots of z_1 and z_2 using ggplot2
ggplot(data = as.data.frame(z_1), aes(x = V1, y=V2)) +
geom_point(color = 'red') +
labs(x = "X-axis", y = "Y-axis", title = "Scatterplot of z_1")
ggplot(data = as.data.frame(z_2), aes(x = V1, y=V2)) +
geom_point(color = 'green') +
labs(x = "X-axis", y = "Y-axis", title = "Scatterplot of z_2")
ggplot(data = as.data.frame(z_1), aes(x = V1, y=V2)) +
geom_point(color = 'red') +
labs(x = "X-axis", y = "Y-axis", title = "Scatterplot of z_1")
+
ggplot(data = as.data.frame(z_2), aes(x = V1, y=V2)) +
geom_point(color = 'green') +
labs(x = "X-axis", y = "Y-axis", title = "Scatterplot of z_2")
plot(z_1, col = '#EE3496', pch=16)
points(z_2, col = '#004D40', pch=16)
#Ejercicio 9)
# Vamos a hacer las cuentas en R para comprobar las propiedades que sugiere
#el ejercicio teórico
install.packages('expm')
library(expm)
#Definimos las matrices, vectores y magnitudes del problema
sigma_w = matrix(c(1,1/2,1/2,1),ncol = 2, nrow = 2)
mu_1 = c(1,1/2)
mu_2 = c(-1/2,1)
pi_1 = 3/4
pi_2 = 1/4
mu_x = pi_1*mu_1 + pi_2*mu_2
sigma_b = pi_1*((mu_1 - mu_x) %*% t(mu_1 - mu_x)) + pi_2*((mu_2 - mu_x) %*% t(mu_2 - mu_x))
#definimos como la matriz C triangular tal que t(C) %*% C recupere sigma_w:
C = sqrtm(sigma_w)
#compruebo:
t(C) %*% C
#me da igual que sigma_w!
#calculo los autovalores y autovectores de B C^(-1) simga_b C que me define la
#magnitud F que quiero maximizar y adopta los valores maximos en sus autovectores:
B = t(solve(C)) %*% sigma_b %*% solve(C)
#calculo ave y ava:
b = eigen(B)
#a continuación defino la matriz A que esta compuesta por los alpha definidos
#como C^(-1)*beta_j con beta_j autovector de B:
A_aux = b$vectors
A = solve(C) %*% A_aux
A
#calculo las cordenadas de los centroides según definicion:
#centroides
v_1 = t(A)%*%mu_1
v_2 = t(A)%*%mu_2
#la ditancia euclidea entre los centroides transformados al espacio de coordenadas
#discriminantes está dado por la norma 2 euclidea:
#distancia euclidea
norm(v_1 - v_2, "2")
#comparo esta magnitud con la distancia de los centroides en el espacio
#original pero calculada con la métrica definida por las covarianzas
#de las variables aleatorias originales:
#distancia mahalanobis
sqrt(t(mu_1-mu_2)%*%solve(sigma_w)%*%(mu_1 - mu_2))
#me da exactamente lo mismo!!
#realizo las simulaciones para probar la version estimada de lo hecho arriba:
## simulación:
library(MASS)
mu_1 = c(1,1/2)
mu_2 = c(-1/2,1)
pi_1 = 3/4
pi_2 = 1/4
mu_x = pi_1*mu_1 + pi_2*mu_2
n_1 = rbinom(1,500,3/4)
n_2 = 500 - n_1
x_group_1 = mvrnorm(n_1, mu = mu_1, Sigma = sigma_w)
x_group_2 = mvrnorm(n_2, mu = mu_2, Sigma = sigma_w)
plot(x_group_1, col = 'red')
points(x_group_2, col = 'green')
x_1_cent = sweep(x_group_1,2,mu_x)
x_2_cent = sweep(x_group_2,2,mu_x)
z_1 =t( t(A)%*%t(x_1_cent)) #el quilombo de transpuestas es culpa de R
z_2 =t( t(A)%*%t(x_2_cent)) #el quilombo de transpuestas es culpa de R
plot(z_1, col = 'red')
points(z_2, col = 'green')
#se observa que la varianza esta "alineada" horizontalmente. Esto ocurre porque
#el segundo autovalor es 0, indicándonos que toda la varianza se explica a partir
#de la primer coordenada discriminante
library(MASS)
library(ggplot2)
mu_1 = c(1,1/2)
mu_2 = c(-1/2,1)
mu = c(5/8, 5/8)
mu_1_ <- mu_1 - mu
mu_2_ <- mu_2 - mu
S_b <- fractions(3/4 * (mu_1_%*%t(mu_1_))) + fractions(1/4 * (mu_2_%*%t(mu_2_)))
S_b
S_w = matrix(c(1,1/2,1/2,1),ncol = 2, nrow = 2)
S_b = matrix(c(-27/64,-9/64,-9/64,3/64),ncol = 2, nrow = 2)
S_aux<-solve(S_w)%*%S_b
fractions(S_aux)
A<-eigen(S_aux)$vectors
fractions(A)
t(A)%*%S_w%*%A
t(A)%*%S_b%*%A
Sx <- S_w+S_b
t(A)%*%Sx%*%A
# Load necessary libraries
library(ggplot2)
library(mvtnorm)
# Set your parameters (make sure you've defined mu_1, mu_2, and S_w)
mu_1 <- c(1, 2)  # Example mean vector for x_1
mu_2 <- c(3, 4)  # Example mean vector for x_2
S_w <- matrix(c(1, 0.5, 0.5, 2), nrow = 2)  # Example covariance matrix
# Generate random data
set.seed(3487)  # for reproducibility
n_1 <- rbinom(1, 500, 3/4)
n_2 <- 500 - n_1
x_1 <- mvrnorm(n_1, mu = mu_1, Sigma = S_w)
x_2 <- mvrnorm(n_2, mu = mu_2, Sigma = S_w)
# Combine the data into a data frame
data <- data.frame(
x = c(x_1[, 1], x_2[, 1]),
y = c(x_1[, 2], x_2[, 2]),
group = factor(rep(c("G=1", "G=2"), c(n_1, n_2)))
)
# Create the scatterplot using ggplot2
scatter_plot<-ggplot(data, aes(x = x, y = y, color = group)) +
geom_point() +
labs(x = "X1", y = "X2", title = "Dispersión de las variables originales") +
scale_color_manual(values = c("G=1" = "#EE349c", "G=2" = "#07004D"))  # Customize colors if needed
# Save the plot to a PDF file
ggsave("scatter_plot.pdf", plot = scatter_plot, width = 8, height = 3)
x_1_ <- sweep(x_1, 2, mu)
x_2_ <- sweep(x_2, 2, mu)
z_1 <- t(t(A)%*%t(x_1_))
z_2 <- t(t(A)%*%t(x_2_))
plot(z_1, col = '#EE3496', pch=16)
points(z_2, col = '#004D40', pch=16)
z_1 <- t(t(A)%*%t(x_1_))
z_2 <- t(t(A)%*%t(x_2_))
zz <- rbind(z_1, z_2)
zz
data <- data.frame(
x = zz[,1],
y = zz[,2],
group = factor(rep(c("G=1", "G=2"), c(length(z_1), length(z_2))))
)
data
View(data)
trans_plot<-ggplot(data, aes(x = x, y = y, color = group)) +
geom_point() +
labs(x = "x", y = "y", title = "Dispersión de las variables transformadas") +
scale_color_manual(values = c("G=1" = "#EE349c", "G=2" = "#07004D"))  # Customize colors if needed
trans_plot
# Save the plot to a PDF file
ggsave("scatter_plot.pdf", plot = trans_plot, width = 8, height = 3)
library(MASS)
library(ggplot2)
mu_1 = c(1,1/2)
mu_2 = c(-1/2,1)
mu = c(5/8, 5/8)
mu_1_ <- mu_1 - mu
mu_2_ <- mu_2 - mu
S_b <- fractions(3/4 * (mu_1_%*%t(mu_1_))) + fractions(1/4 * (mu_2_%*%t(mu_2_)))
S_b
S_w = matrix(c(1,1/2,1/2,1),ncol = 2, nrow = 2)
S_b = matrix(c(-27/64,-9/64,-9/64,3/64),ncol = 2, nrow = 2)
S_aux<-solve(S_w)%*%S_b
fractions(S_aux)
A<-eigen(S_aux)$vectors
fractions(A)
t(A)%*%S_w%*%A
t(A)%*%S_b%*%A
Sx <- S_w+S_b
t(A)%*%Sx%*%A
# Load necessary libraries
library(ggplot2)
library(mvtnorm)
# Set your parameters (make sure you've defined mu_1, mu_2, and S_w)
mu_1 <- c(1, 2)  # Example mean vector for x_1
mu_2 <- c(3, 4)  # Example mean vector for x_2
S_w <- matrix(c(1, 0.5, 0.5, 2), nrow = 2)  # Example covariance matrix
# Generate random data
set.seed(3487)  # for reproducibility
n_1 <- rbinom(1, 500, 3/4)
n_2 <- 500 - n_1
x_1 <- mvrnorm(n_1, mu = mu_1, Sigma = S_w)
x_2 <- mvrnorm(n_2, mu = mu_2, Sigma = S_w)
# Combine the data into a data frame
data <- data.frame(
x = c(x_1[, 1], x_2[, 1]),
y = c(x_1[, 2], x_2[, 2]),
group = factor(rep(c("G=1", "G=2"), c(n_1, n_2)))
)
# Create the scatterplot using ggplot2
scatter_plot<-ggplot(data, aes(x = x, y = y, color = group)) +
geom_point() +
labs(x = "X1", y = "X2", title = "Dispersión de las variables originales") +
scale_color_manual(values = c("G=1" = "#EE349c", "G=2" = "#07004D"))  # Customize colors if needed
# Save the plot to a PDF file
ggsave("scatter_plot.pdf", plot = scatter_plot, width = 8, height = 3)
x_1_ <- sweep(x_1, 2, mu)
x_2_ <- sweep(x_2, 2, mu)
z_1 <- t(t(A)%*%t(x_1_))
z_2 <- t(t(A)%*%t(x_2_))
zz <- rbind(z_1, z_2)
data <- data.frame(
x = zz[,1],
y = zz[,2],
group = factor(rep(c("G=1", "G=2"), c(length(z_1), length(z_2))))
)
trans_plot<-ggplot(data, aes(x = x, y = y, color = group)) +
geom_point() +
labs(x = "x", y = "y", title = "Dispersión de las variables transformadas") +
scale_color_manual(values = c("G=1" = "#EE349c", "G=2" = "#07004D"))  # Customize colors if needed
trans_plot
# Save the plot to a PDF file
ggsave("scatter_plot.pdf", plot = trans_plot, width = 8, height = 3)
plot(z_1, col = '#EE3496', pch=16)
points(z_2, col = '#004D40', pch=16)
A
#definimos como la matriz C triangular tal que t(C) %*% C recupere sigma_w:
C = sqrtm(S_w)
#compruebo:
t(C) %*% C
#calculo los autovalores y autovectores de B C^(-1) simga_b C que me define la
#magnitud F que quiero maximizar y adopta los valores maximos en sus autovectores:
B = t(solve(C)) %*% sigma_b %*% solve(C)
library(MASS)
library(ggplot2)
mu_1 = c(1,1/2)
mu_2 = c(-1/2,1)
mu = c(5/8, 5/8)
mu_1_ <- mu_1 - mu
mu_2_ <- mu_2 - mu
S_b <- fractions(3/4 * (mu_1_%*%t(mu_1_))) + fractions(1/4 * (mu_2_%*%t(mu_2_)))
S_b
S_w = matrix(c(1,1/2,1/2,1),ncol = 2, nrow = 2)
S_b = matrix(c(-27/64,-9/64,-9/64,3/64),ncol = 2, nrow = 2)
S_aux<-solve(S_w)%*%S_b
fractions(S_aux)
#definimos como la matriz C triangular tal que t(C) %*% C recupere sigma_w:
C = sqrtm(S_w)
#compruebo:
t(C) %*% C
#me da igual que sigma_w!
#calculo los autovalores y autovectores de B C^(-1) simga_b C que me define la
#magnitud F que quiero maximizar y adopta los valores maximos en sus autovectores:
B = t(solve(C)) %*% S_b %*% solve(C)
#calculo ave y ava:
b = eigen(B)
#a continuación defino la matriz A que esta compuesta por los alpha definidos
#como C^(-1)*beta_j con beta_j autovector de B:
A_aux = b$vectors
A = solve(C) %*% A_aux
A
fraction(A)
fractions(A)
#A<-eigen(S_aux)$vectors
#fractions(A)
t(A)%*%S_w%*%A
t(A)%*%S_b%*%A
Sx <- S_w+S_b
t(A)%*%Sx%*%A
#Ejercicio 9)
# Vamos a hacer las cuentas en R para comprobar las propiedades que sugiere
#el ejercicio teórico
install.packages('expm')
library(expm)
#Definimos las matrices, vectores y magnitudes del problema
sigma_w = matrix(c(1,1/2,1/2,1),ncol = 2, nrow = 2)
mu_1 = c(1,1/2)
mu_2 = c(-1/2,1)
pi_1 = 3/4
pi_2 = 1/4
mu_x = pi_1*mu_1 + pi_2*mu_2
sigma_b = pi_1*((mu_1 - mu_x) %*% t(mu_1 - mu_x)) + pi_2*((mu_2 - mu_x) %*% t(mu_2 - mu_x))
#definimos como la matriz C triangular tal que t(C) %*% C recupere sigma_w:
C = sqrtm(sigma_w)
install.packages("expm")
#Ejercicio 9)
# Vamos a hacer las cuentas en R para comprobar las propiedades que sugiere
#el ejercicio teórico
install.packages('expm')
library(expm)
#Definimos las matrices, vectores y magnitudes del problema
sigma_w = matrix(c(1,1/2,1/2,1),ncol = 2, nrow = 2)
mu_1 = c(1,1/2)
mu_2 = c(-1/2,1)
pi_1 = 3/4
pi_2 = 1/4
mu_x = pi_1*mu_1 + pi_2*mu_2
sigma_b = pi_1*((mu_1 - mu_x) %*% t(mu_1 - mu_x)) + pi_2*((mu_2 - mu_x) %*% t(mu_2 - mu_x))
#definimos como la matriz C triangular tal que t(C) %*% C recupere sigma_w:
C = sqrtm(sigma_w)
C
#definimos como la matriz C triangular tal que t(C) %*% C recupere sigma_w:
library(MASS)
fractions(C)
#compruebo:
t(C) %*% C
#me da igual que sigma_w!
#calculo los autovalores y autovectores de B C^(-1) simga_b C que me define la
#magnitud F que quiero maximizar y adopta los valores maximos en sus autovectores:
B = t(solve(C)) %*% sigma_b %*% solve(C)
B
b = eigen(B)
#a continuación defino la matriz A que esta compuesta por los alpha definidos
#como C^(-1)*beta_j con beta_j autovector de B:
A_aux = b$vectors
A = solve(C) %*% A_aux
A
fractions(A)
#calculo las cordenadas de los centroides según definicion:
#centroides
v_1 = t(A)%*%mu_1
v_2 = t(A)%*%mu_2
v_1
v_1
v_2
#distancia euclidea
norm(v_1 - v_2, "2")
#distancia mahalanobis
sqrt(t(mu_1-mu_2)%*%solve(sigma_w)%*%(mu_1 - mu_2))
mu_1
mu_1-mu_2
\solve(sigma_w)
solve(sigma_w)
fractions(solve(sigma_w))
t(A)%*%sigma_w%*%A
t(A)%*%(sigma_w+sigma_b)%*%A
t(A)%*%sigma_b%*%A
t(A)%*%sigma_w%*%A
t(A)%*%(sigma_w+sigma_b)%*%A
#realizo las simulaciones para probar la version estimada de lo hecho arriba:
## simulación:
library(MASS)
n_1 = rbinom(1,500,3/4)
n_2 = 500 - n_1
x_group_1 = mvrnorm(n_1, mu = mu_1, Sigma = sigma_w)
x_group_2 = mvrnorm(n_2, mu = mu_2, Sigma = sigma_w)
plot(x_group_1, col = 'red')
points(x_group_2, col = 'green')
x_1_cent = sweep(x_group_1,2,mu_x)
x_2_cent = sweep(x_group_2,2,mu_x)
z_1 =t( t(A)%*%t(x_1_cent)) #el quilombo de transpuestas es culpa de R
z_2 =t( t(A)%*%t(x_2_cent)) #el quilombo de transpuestas es culpa de R
plot(z_1, col = 'red')
points(z_2, col = 'green')
#se observa que la varianza esta "alineada" horizontalmente. Esto ocurre porque
#el segundo autovalor es 0, indicándonos que toda la varianza se explica a partir
#de la primer coordenada discriminante
zz <- data.frame(x=zz[,1], y=zz[,2], grupo=rep("G=1", "G=2", c(length(z1), length(z_2))))
data <- rbind(z_1, z_2)
zz <- data.frame(x=zz[,1], y=zz[,2], grupo=rep("G=1", "G=2", c(length(z_1), length(z_2))))
zz <- data.frame(x=data[,1], y=data[,2], grupo=rep("G=1", "G=2", c(length(z_1), length(z_2))))
data <- rbind(z_1, z_2)
zz <- data.frame(x=data[,1], y=data[,2], grupo=rep("G=1", "G=2", c(length(z_1), length(z_2))))
length(z_1)
zz <- data.frame(x=data[,1], y=data[,2], grupo=rep("G=1", "G=2", c(nrow(z_1), length(z_2))))
nrow(z_1)
zz <- data.frame(x=data[,1], y=data[,2], grupo=rep("G=1", "G=2", c(nrow(z_1), nrow(z_2))))
c(nrow(z_1), nrow(z_2))
zz <- data.frame(x=data[,1], y=data[,2], grupo=rep(c("G=1", "G=2"), c(nrow(z_1), nrow(z_2))))
scatter_plot<-ggplot(data, aes(x = x, y = y, color = grupo)) +
geom_point() +
labs(x = "z1", y = "z2", title = "Dispersión de las variables transformadas") +
scale_color_manual(values = c("G=1" = "#EE349c", "G=2" = "#07004D"))
library(gglot2)
library(ggplot2)
scatter_plot<-ggplot(data, aes(x = x, y = y, color = grupo)) +
geom_point() +
labs(x = "z1", y = "z2", title = "Dispersión de las variables transformadas") +
scale_color_manual(values = c("G=1" = "#EE349c", "G=2" = "#07004D"))
scatter_plot<-ggplot(zz, aes(x = x, y = y, color = grupo)) +
geom_point() +
labs(x = "z1", y = "z2", title = "Dispersión de las variables transformadas") +
scale_color_manual(values = c("G=1" = "#EE349c", "G=2" = "#07004D"))
scatter_plot
ggsave("scatter_plot_trans.pdf", plot = scatter_plot, width = 8, height = 3)
b$values
b
# Práctica 2
library('tidyverse')
library(tibble)
library(rlang)
install.packages("tidyverse")
options(repos = c(REPO_NAME = "https://packagemanager.rstudio.com/cran/latest"))
install.packages("tidyverse")
install.packages("tidyverse")
setwd("/home/mailen/Documents/MEM/TRVD/Clase 4/")
#Men's Olympic Decathlon Data from 1988
#Data from men's 1988 Olympic decathlon
#Total of n = 34 athletes
#Have p = 10 variables giving score for each decathlon
#event Have overall decathlon score
#also (score)
library(ade4)
data(olympic)
aa<-data.frame(olympic$tab)
names(olympic)
head(olympic$tab)
summary(olympic$tab)
# Variables asociadas con running  (100, 400, 110, y 1500),
# bajos puntos corresponden a mejor performance pero para las otras disciplinas
# es al revez
#Entonces para tener una interpretacion mas facil le cambiamos el signo a estas variables
olympic$tab[,c(1,5,6,10)]<- -olympic$tab[,c(1,5,6,10)]
X<-olympic$tab[,c( "poid",  "disq" ,"perc", "jave")]
Y<-olympic$tab[,c("100",  "long","haut", "400" , "110",   "1500")]
n <- nrow(X) # n = 33
p <- ncol(X) # p = 4
q <- ncol(Y) # q = 6
library(CCA)
correl <- matcor(X, Y)
correl
correl <- matcor(X, Y)
??matcor
library(CCA)
library(CCA)
correl <- matcor(X, Y)
correl
img.matcor(correl, type = 2)
# CC a mano (sin estandarizar las variables)
Sx <- cov(X) #var(X) es lo mismo
Sy <- cov(Y)
Sxy <- cov(X,Y)
# CC a mano (sin estandarizar las variables)
Sx <- cov(X) #var(X) es lo mismo
Sy <- cov(Y)
Sxy <- cov(X,Y)
Sxeig <- eigen(Sx)
SxI <- Sxeig$vectors %*% diag(1/Sxeig$values) %*% t(Sxeig$vectors)
Syeig <- eigen(Sy)
SyI <- Syeig$vectors %*% diag(1/(Syeig$values)) %*% t(Syeig$vectors)
Xmat <- SxI %*% Sxy %*% SyI %*% t(Sxy)
Ymat <- SyI %*% t(Sxy) %*% SxI %*% Sxy
Xeig <- eigen(Xmat)
Yeig <- eigen(Ymat)
Xeig$values
Yeig$values
# Usamos la funcion cancor
ccaXY <- cancor(X, Y)
names(ccaXY)
# o bien
ccXY<-cc(X,Y)
names(ccXY)
# comparamos las correlaciones al cuadrado
Xeig$values
ccaXY$cor^2
ccXY$cor^2
XautovecST<-Xeig$vectors%*%diag(1/sqrt(diag( t(Xeig$vectors)%*%Sx%*%Xeig$vectors)))
YautovecST<-Yeig$vectors%*%diag(1/sqrt(diag( t(Yeig$vectors)%*%Sy%*%Yeig$vectors)))
XautovecST
YautovecST
# que coinciden con
ccXY$xcoef
ccXY$ycoef
ccaXY$xcoef*sqrt(n-1)
ccaXY$ycoef*sqrt(n-1)
names(ccXY)
ccXY$xcoef
ccXY$ycoef
plot(ccXY$cor, type = "b")
ccXY$cor
plot(ccXY$scores$xscores[,1],ccXY$scores$yscores[,1])
plot(ccXY$scores$xscores[,2],ccXY$scores$yscores[,2])
plot(ccXY$scores$xscores[,3],ccXY$scores$yscores[,3])
plot(ccXY$scores$xscores[,4],ccXY$scores$yscores[,4])
plt.cc(ccXY,var.label=TRUE)
plt.var(ccXY,d1=1,d2=1,var.label=TRUE)
require(vegan)
cca2 <- CCorA(X,Y)
biplot(cca2)
?cancor
names(ccaXY)
# comparamos las correlaciones al cuadrado
Xeig$values
ccaXY$cor^2
ccXY$cor^2
plot(ccXY$cor, type = "b")
plot(ccXY$scores$xscores[,1],ccXY$scores$yscores[,1])
plot(ccXY$scores$xscores[,2],ccXY$scores$yscores[,2])
plot(ccXY$scores$xscores[,3],ccXY$scores$yscores[,3])
plot(ccXY$scores$xscores[,4],ccXY$scores$yscores[,4])
plt.cc(ccXY,var.label=TRUE)
plt.var(ccXY,d1=1,d2=1,var.label=TRUE)
cca2 <- CCorA(X,Y)
biplot(cca2)
